{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering-exps-mnist5-PCA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMVxeD4vXAZB",
        "cellView": "form",
        "outputId": "d8084b09-a391-4193-e408-013b62b38d2a"
      },
      "source": [
        "#@title Don't forget to upload usps.h5\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "def purity_score(y_true, y_pred): # from https://stackoverflow.com/a/51672699/7947996; in [0,1]; 0-bad,1-good\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    # return purity\n",
        "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
        "\n",
        "from sklearn.metrics.cluster import adjusted_rand_score # in [0,1]; 0-bad,1-good\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score # in [0,1]; 0-bad,1-good\n",
        "\n",
        "!pip install coclust\n",
        "from coclust.evaluation.external import accuracy # in [0,1]; 0-bad,1-good\n",
        "\n",
        "def get_data_20news():\n",
        "  import tensorflow as tf\n",
        "  from sklearn.datasets import fetch_20newsgroups\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "  _20news = fetch_20newsgroups(subset=\"all\")\n",
        "  data = _20news.data\n",
        "  target = _20news.target\n",
        "\n",
        "  vectorizer = TfidfVectorizer(max_features=2000)\n",
        "  data = vectorizer.fit_transform(data)\n",
        "  data = data.toarray()\n",
        "\n",
        "  return data, target\n",
        "\n",
        "\n",
        "def get_data_mnist():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.mnist\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "\n",
        "  real_labels = y_train\n",
        "\n",
        "  # # indices = np.isin(y_train,range(number_of_dist))\n",
        "  # x_train = x_train[indices]\n",
        "  # y_train = y_train[indices]\n",
        "\n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_mnist5():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.mnist\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "\n",
        "  indices = y_train < 5\n",
        "  x_train = x_train[indices]\n",
        "  y_train = y_train[indices]\n",
        "\n",
        "  real_labels = y_train\n",
        "  \n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_fmnist():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.fashion_mnist\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "\n",
        "  real_labels = y_train\n",
        "\n",
        "  # # indices = np.isin(y_train,range(number_of_dist))\n",
        "  # x_train = x_train[indices]\n",
        "  # y_train = y_train[indices]\n",
        "\n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_usps():\n",
        "  import h5py\n",
        "  path = \"./usps.h5\"\n",
        "  with h5py.File(path, 'r') as hf:\n",
        "    train = hf.get('train')\n",
        "    X_tr = train.get('data')[:]\n",
        "    y_tr = train.get('target')[:]\n",
        "    test = hf.get('test')\n",
        "    X_te = test.get('data')[:]\n",
        "    y_te = test.get('target')[:]\n",
        "\n",
        "  samples = np.concatenate((X_tr,X_te))\n",
        "  real_labels = np.concatenate((y_tr,y_te))\n",
        "  return samples, real_labels\n",
        "\n",
        "original_data_name = \"mnist5\" # @param [\"mnist\", \"mnist5\", \"fmnist\", \"20news\", \"usps\"]\n",
        "\n",
        "if original_data_name == \"mnist\":\n",
        "    samples, real_labels = get_data_mnist()\n",
        "elif original_data_name == \"mnist5\":\n",
        "    samples, real_labels = get_data_mnist5()\n",
        "elif original_data_name == \"fmnist\":\n",
        "    samples, real_labels = get_data_fmnist()\n",
        "elif original_data_name == \"20news\":\n",
        "    samples, real_labels = get_data_20news()\n",
        "elif original_data_name == \"usps\":\n",
        "    samples, real_labels = get_data_usps()\n",
        "  \n",
        "k = len(np.unique(real_labels))\n",
        "n_init = 10\n",
        "dim_pca = 100\n",
        "\n",
        "if dim_pca is not None:\n",
        "    import numpy as np\n",
        "    from sklearn.decomposition import PCA\n",
        "    X = samples\n",
        "    pca = PCA(n_components=dim_pca)\n",
        "    samples = pca.fit_transform(X)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: coclust in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from coclust) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from coclust) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from coclust) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->coclust) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM2n39n8x0fE"
      },
      "source": [
        "### Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExRzemEgvWeb",
        "outputId": "4e33648d-c344-4b79-d363-6a14aa38fae4"
      },
      "source": [
        "predicted_random = np.random.randint(k,size=len(real_labels))\n",
        "\n",
        "print(purity_score(real_labels,predicted_random))\n",
        "print(adjusted_rand_score(real_labels,predicted_random))\n",
        "print(normalized_mutual_info_score(real_labels,predicted_random))\n",
        "print(accuracy(real_labels,predicted_random))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22042815167203023\n",
            "-2.5435655715452638e-05\n",
            "0.00010758729404844848\n",
            "0.20481320833916328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE1OLiiGx3Tl"
      },
      "source": [
        "### k-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fSvnYVhb930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dabf663d-0bf2-4c32-d40f-bb3e4d50d83e"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "X = samples\n",
        "kmeans = KMeans(n_clusters=k,n_init=n_init).fit(X)\n",
        "predicted_km = kmeans.predict(X)\n",
        "\n",
        "print(purity_score(real_labels,predicted_km))\n",
        "print(adjusted_rand_score(real_labels,predicted_km))\n",
        "print(normalized_mutual_info_score(real_labels,predicted_km))\n",
        "print(accuracy(real_labels,predicted_km))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8810969637610186\n",
            "0.7325175963854366\n",
            "0.7099972651849052\n",
            "0.8810969637610186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9XY7cupOKay",
        "outputId": "eb488971-b83a-4c61-a83a-b0c2f5dc5656"
      },
      "source": [
        "import sklearn.metrics\n",
        "matrix = sklearn.metrics.cluster.contingency_matrix(real_labels, predicted_km)\n",
        "print(matrix)\n",
        "print(matrix/matrix.sum(axis=1, keepdims=True))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 248   21 6131  115  388]\n",
            " [ 119 7702    0   17   39]\n",
            " [5134  787   94  379  596]\n",
            " [ 495  401   45  176 6024]\n",
            " [  41  268   15 6495    5]]\n",
            "[[3.59264088e-02 3.04215558e-03 8.88164566e-01 1.66594234e-02\n",
            "  5.62074460e-02]\n",
            " [1.51072743e-02 9.77783420e-01 0.00000000e+00 2.15818205e-03\n",
            "  4.95112352e-03]\n",
            " [7.34477825e-01 1.12589413e-01 1.34477825e-02 5.42203147e-02\n",
            "  8.52646638e-02]\n",
            " [6.93180227e-02 5.61546002e-02 6.30163843e-03 2.46464081e-02\n",
            "  8.43579331e-01]\n",
            " [6.00820633e-03 3.92731536e-02 2.19812427e-03 9.51787808e-01\n",
            "  7.32708089e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57lT0F8Mx4Fh"
      },
      "source": [
        "### GMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxjlKBYscsE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0647d33f-a5fb-40b0-fdb7-7e09a2452f1c"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "X = samples\n",
        "gm = GaussianMixture(n_components=k,n_init=n_init).fit(X)\n",
        "predicted_gmm = gm.predict(X)\n",
        "\n",
        "print(purity_score(real_labels,predicted_gmm))\n",
        "print(adjusted_rand_score(real_labels,predicted_gmm))\n",
        "print(normalized_mutual_info_score(real_labels,predicted_gmm))\n",
        "print(accuracy(real_labels,predicted_gmm))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8650622638869456\n",
            "0.6773498866819344\n",
            "0.7357071788402717\n",
            "0.8650622638869456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOjm81-zyy3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bae44d2-9e33-4501-90b4-a2d26fbbc9cc"
      },
      "source": [
        "import sklearn.metrics\n",
        "matrix = sklearn.metrics.cluster.contingency_matrix(real_labels, predicted_gmm)\n",
        "print(matrix)\n",
        "print(matrix/matrix.sum(axis=1, keepdims=True))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 788 6106    0    4    5]\n",
            " [ 797    0 6188    3  889]\n",
            " [6959    3    0    9   19]\n",
            " [1136    9    1 5952   43]\n",
            " [1115    0    1    0 5708]]\n",
            "[[1.14153267e-01 8.84542952e-01 0.00000000e+00 5.79458207e-04\n",
            "  7.24322758e-04]\n",
            " [1.01180653e-01 0.00000000e+00 7.85578266e-01 3.80855656e-04\n",
            "  1.12860226e-01]\n",
            " [9.95565093e-01 4.29184549e-04 0.00000000e+00 1.28755365e-03\n",
            "  2.71816881e-03]\n",
            " [1.59081361e-01 1.26032769e-03 1.40036409e-04 8.33496709e-01\n",
            "  6.02156561e-03]\n",
            " [1.63393904e-01 0.00000000e+00 1.46541618e-04 0.00000000e+00\n",
            "  8.36459555e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}