{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering-exps-cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMVxeD4vXAZB",
        "cellView": "form",
        "outputId": "1b15e13e-fe04-407d-c110-f425b7d56ecb"
      },
      "source": [
        "#@title Don't forget to upload usps.h5\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "def purity_score(y_true, y_pred): # from https://stackoverflow.com/a/51672699/7947996; in [0,1]; 0-bad,1-good\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    # return purity\n",
        "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
        "\n",
        "from sklearn.metrics.cluster import adjusted_rand_score # in [0,1]; 0-bad,1-good\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score # in [0,1]; 0-bad,1-good\n",
        "\n",
        "!pip install coclust\n",
        "from coclust.evaluation.external import accuracy # in [0,1]; 0-bad,1-good\n",
        "\n",
        "def get_data_20news():\n",
        "  import tensorflow as tf\n",
        "  from sklearn.datasets import fetch_20newsgroups\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "  _20news = fetch_20newsgroups(subset=\"all\")\n",
        "  data = _20news.data\n",
        "  target = _20news.target\n",
        "\n",
        "  vectorizer = TfidfVectorizer(max_features=2000)\n",
        "  data = vectorizer.fit_transform(data)\n",
        "  data = data.toarray()\n",
        "\n",
        "  return data, target\n",
        "\n",
        "\n",
        "def get_data_mnist():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.mnist\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "\n",
        "  real_labels = y_train\n",
        "\n",
        "  # # indices = np.isin(y_train,range(number_of_dist))\n",
        "  # x_train = x_train[indices]\n",
        "  # y_train = y_train[indices]\n",
        "\n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_cifar10():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.cifar10\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "  y_train = y_train.squeeze()\n",
        "\n",
        "  real_labels = y_train\n",
        "\n",
        "  # # indices = np.isin(y_train,range(number_of_dist))\n",
        "  # x_train = x_train[indices]\n",
        "  # y_train = y_train[indices]\n",
        "\n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_mnist5():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.mnist\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "\n",
        "  indices = y_train < 5\n",
        "  x_train = x_train[indices]\n",
        "  y_train = y_train[indices]\n",
        "\n",
        "  real_labels = y_train\n",
        "\n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_fmnist():\n",
        "  import tensorflow as tf\n",
        "  mnist = tf.keras.datasets.fashion_mnist\n",
        "  (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = np.concatenate((x_train,x_test))\n",
        "  y_train = np.concatenate((y_train,y_test))\n",
        "\n",
        "  real_labels = y_train\n",
        "\n",
        "  # # indices = np.isin(y_train,range(number_of_dist))\n",
        "  # x_train = x_train[indices]\n",
        "  # y_train = y_train[indices]\n",
        "\n",
        "  samples = (x_train.reshape((x_train.shape[0],-1))/255.).astype(np.float32)\n",
        "  \n",
        "  return samples, real_labels\n",
        "\n",
        "def get_data_usps():\n",
        "  import h5py\n",
        "  path = \"./usps.h5\"\n",
        "  with h5py.File(path, 'r') as hf:\n",
        "    train = hf.get('train')\n",
        "    X_tr = train.get('data')[:]\n",
        "    y_tr = train.get('target')[:]\n",
        "    test = hf.get('test')\n",
        "    X_te = test.get('data')[:]\n",
        "    y_te = test.get('target')[:]\n",
        "\n",
        "  samples = np.concatenate((X_tr,X_te))\n",
        "  real_labels = np.concatenate((y_tr,y_te))\n",
        "  return samples, real_labels\n",
        "\n",
        "original_data_name = \"cifar10\" # @param [\"mnist\", \"mnist5\", \"cifar10\", \"fmnist\", \"20news\", \"usps\"]\n",
        "\n",
        "if original_data_name == \"mnist\":\n",
        "    samples, real_labels = get_data_mnist()\n",
        "elif original_data_name == \"mnist5\":\n",
        "    samples, real_labels = get_data_mnist5()\n",
        "elif original_data_name == \"cifar10\":\n",
        "    samples, real_labels = get_data_cifar10()\n",
        "elif original_data_name == \"fmnist\":\n",
        "    samples, real_labels = get_data_fmnist()\n",
        "elif original_data_name == \"20news\":\n",
        "    samples, real_labels = get_data_20news()\n",
        "elif original_data_name == \"usps\":\n",
        "    samples, real_labels = get_data_usps()\n",
        "\n",
        "  \n",
        "k = len(np.unique(real_labels))\n",
        "n_init = 10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ymatbridge (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ymatbridge (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ymatbridge (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ymatbridge (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ymatbridge (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ymatbridge (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -umpy (c:\\users\\sebi\\anaconda3\\lib\\site-packages)\n",
            "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: coclust in c:\\users\\sebi\\anaconda3\\lib\\site-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\sebi\\anaconda3\\lib\\site-packages (from coclust) (1.18.5)\n",
            "Requirement already satisfied: scipy in c:\\users\\sebi\\anaconda3\\lib\\site-packages (from coclust) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\sebi\\anaconda3\\lib\\site-packages (from coclust) (0.22.2)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\sebi\\anaconda3\\lib\\site-packages (from scikit-learn->coclust) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM2n39n8x0fE"
      },
      "source": [
        "### Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExRzemEgvWeb",
        "outputId": "3faa02f1-9b35-4fe5-b2f7-ae60b0173254"
      },
      "source": [
        "predicted_random = np.random.randint(k,size=len(real_labels))\n",
        "\n",
        "print(purity_score(real_labels,predicted_random))\n",
        "print(adjusted_rand_score(real_labels,predicted_random))\n",
        "print(normalized_mutual_info_score(real_labels,predicted_random))\n",
        "print(accuracy(real_labels,predicted_random))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10635\n",
            "2.997195984511677e-05\n",
            "0.00035189400777027184\n",
            "0.10553333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE1OLiiGx3Tl"
      },
      "source": [
        "### k-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fSvnYVhb930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140c5526-3c9c-4fac-f90a-46ad902a0032"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "X = samples\n",
        "kmeans = KMeans(n_clusters=k,n_init=n_init).fit(X)\n",
        "predicted_km = kmeans.predict(X)\n",
        "\n",
        "print(purity_score(real_labels,predicted_km))\n",
        "print(adjusted_rand_score(real_labels,predicted_km))\n",
        "print(normalized_mutual_info_score(real_labels,predicted_km))\n",
        "print(accuracy(real_labels,predicted_km))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22121666666666667\n",
            "0.0417808638470051\n",
            "0.07932388205690752\n",
            "0.20623333333333332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9XY7cupOKay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c43813-63b7-4b58-aec3-2e392c0bd821"
      },
      "source": [
        "import sklearn.metrics\n",
        "matrix = sklearn.metrics.cluster.contingency_matrix(real_labels, predicted_km)\n",
        "print(matrix)\n",
        "print(matrix/matrix.sum(axis=1, keepdims=True))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 642  912  592  161  485 1188  272  347 1154  247]\n",
            " [1028  588  996  455  490  184  892  518  258  591]\n",
            " [ 393  213  324  410  356  650 1087 1404  446  717]\n",
            " [ 580  143  393  900  460  550  856  979  309  830]\n",
            " [ 308  205  335 1115  212  393 1243 1325  140  724]\n",
            " [1037  112  248 1013  339  733  676  982  198  662]\n",
            " [ 450   53  174  553  459  170 1424 1226  207 1284]\n",
            " [ 477  253  857  884  683  366  764 1202  140  374]\n",
            " [1011 1889 1093  253  210  635  193  209  283  224]\n",
            " [ 493  907 2056  192  722  167  637  466  200  160]]\n",
            "[[0.107      0.152      0.09866667 0.02683333 0.08083333 0.198\n",
            "  0.04533333 0.05783333 0.19233333 0.04116667]\n",
            " [0.17133333 0.098      0.166      0.07583333 0.08166667 0.03066667\n",
            "  0.14866667 0.08633333 0.043      0.0985    ]\n",
            " [0.0655     0.0355     0.054      0.06833333 0.05933333 0.10833333\n",
            "  0.18116667 0.234      0.07433333 0.1195    ]\n",
            " [0.09666667 0.02383333 0.0655     0.15       0.07666667 0.09166667\n",
            "  0.14266667 0.16316667 0.0515     0.13833333]\n",
            " [0.05133333 0.03416667 0.05583333 0.18583333 0.03533333 0.0655\n",
            "  0.20716667 0.22083333 0.02333333 0.12066667]\n",
            " [0.17283333 0.01866667 0.04133333 0.16883333 0.0565     0.12216667\n",
            "  0.11266667 0.16366667 0.033      0.11033333]\n",
            " [0.075      0.00883333 0.029      0.09216667 0.0765     0.02833333\n",
            "  0.23733333 0.20433333 0.0345     0.214     ]\n",
            " [0.0795     0.04216667 0.14283333 0.14733333 0.11383333 0.061\n",
            "  0.12733333 0.20033333 0.02333333 0.06233333]\n",
            " [0.1685     0.31483333 0.18216667 0.04216667 0.035      0.10583333\n",
            "  0.03216667 0.03483333 0.04716667 0.03733333]\n",
            " [0.08216667 0.15116667 0.34266667 0.032      0.12033333 0.02783333\n",
            "  0.10616667 0.07766667 0.03333333 0.02666667]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57lT0F8Mx4Fh"
      },
      "source": [
        "### GMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxjlKBYscsE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6225976d-b873-486d-959d-623c03816f49"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "X = samples\n",
        "gm = GaussianMixture(n_components=k,n_init=n_init).fit(X)\n",
        "predicted_gmm = gm.predict(X)\n",
        "\n",
        "print(purity_score(real_labels,predicted_gmm))\n",
        "print(adjusted_rand_score(real_labels,predicted_gmm))\n",
        "print(normalized_mutual_info_score(real_labels,predicted_gmm))\n",
        "print(accuracy(real_labels,predicted_gmm))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.20651666666666665\n",
            "0.0226805969131825\n",
            "0.05698943167015307\n",
            "0.19153333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljFdEG-YOUpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f44fcf-3a4c-45fb-f5d9-e29de1b87919"
      },
      "source": [
        "import sklearn.metrics\n",
        "matrix = sklearn.metrics.cluster.contingency_matrix(real_labels, predicted_km)\n",
        "print(matrix)\n",
        "print(matrix/matrix.sum(axis=1, keepdims=True))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 642  912  592  161  485 1188  272  347 1154  247]\n",
            " [1028  588  996  455  490  184  892  518  258  591]\n",
            " [ 393  213  324  410  356  650 1087 1404  446  717]\n",
            " [ 580  143  393  900  460  550  856  979  309  830]\n",
            " [ 308  205  335 1115  212  393 1243 1325  140  724]\n",
            " [1037  112  248 1013  339  733  676  982  198  662]\n",
            " [ 450   53  174  553  459  170 1424 1226  207 1284]\n",
            " [ 477  253  857  884  683  366  764 1202  140  374]\n",
            " [1011 1889 1093  253  210  635  193  209  283  224]\n",
            " [ 493  907 2056  192  722  167  637  466  200  160]]\n",
            "[[0.107      0.152      0.09866667 0.02683333 0.08083333 0.198\n",
            "  0.04533333 0.05783333 0.19233333 0.04116667]\n",
            " [0.17133333 0.098      0.166      0.07583333 0.08166667 0.03066667\n",
            "  0.14866667 0.08633333 0.043      0.0985    ]\n",
            " [0.0655     0.0355     0.054      0.06833333 0.05933333 0.10833333\n",
            "  0.18116667 0.234      0.07433333 0.1195    ]\n",
            " [0.09666667 0.02383333 0.0655     0.15       0.07666667 0.09166667\n",
            "  0.14266667 0.16316667 0.0515     0.13833333]\n",
            " [0.05133333 0.03416667 0.05583333 0.18583333 0.03533333 0.0655\n",
            "  0.20716667 0.22083333 0.02333333 0.12066667]\n",
            " [0.17283333 0.01866667 0.04133333 0.16883333 0.0565     0.12216667\n",
            "  0.11266667 0.16366667 0.033      0.11033333]\n",
            " [0.075      0.00883333 0.029      0.09216667 0.0765     0.02833333\n",
            "  0.23733333 0.20433333 0.0345     0.214     ]\n",
            " [0.0795     0.04216667 0.14283333 0.14733333 0.11383333 0.061\n",
            "  0.12733333 0.20033333 0.02333333 0.06233333]\n",
            " [0.1685     0.31483333 0.18216667 0.04216667 0.035      0.10583333\n",
            "  0.03216667 0.03483333 0.04716667 0.03733333]\n",
            " [0.08216667 0.15116667 0.34266667 0.032      0.12033333 0.02783333\n",
            "  0.10616667 0.07766667 0.03333333 0.02666667]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOjm81-zyy3q"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}